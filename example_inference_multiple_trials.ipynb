{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa2ae0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5016bfc",
   "metadata": {},
   "source": [
    "LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f278711",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:05<00:00,  1.36s/it]\n"
     ]
    }
   ],
   "source": [
    "model_id = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "if tokenizer.pad_token_id is None:\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "\n",
    "gpu = 7\n",
    "device = f\"cuda:{gpu}\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model_nf4 = transformers.AutoModelForCausalLM.from_pretrained(model_id, \n",
    "                                                 device_map={\"\": device})\n",
    "\n",
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model= model_nf4, #model_id,\n",
    "    tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5fbe403e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def questions_answers(text):\n",
    "    messages = [\n",
    "    #    {\"role\": \"system\", \"content\": \"You are an expert in creating key questions from a medical text and extract the answers from the text. Extract 3-10 Q/A pairs without repititions of key entities in the Q/As. Avoid general questions like 'What is the exclusion criteria?'. Make sure an answer is NO MORE than 5 tokens/words. Output as json format like this: {'Question': 'question1', 'Answer': 'answer1', 'Question': 'question2' , 'Answer': 'answer2', ...} \\n Input: \"},\n",
    "        {\"role\": \"system\", \"content\": \"You are an expert in creating key questions from a medical text and extract the answers from the text. Extract 3-10 Q/A pairs without repititions of key entities in the Q/As. Avoid general questions like 'What is the exclusion criteria?'. Make sure an answer is NO MORE than 5 tokens/words. Output ONLY json formated Q/A pairs like this: {'Question': 'question1', 'Answer': 'answer1'} \\n {'Question': 'question2' , 'Answer': 'answer2'} \\n ... \\n Input: \"},\n",
    "        {\"role\": \"user\", \"content\": text}]\n",
    "    \n",
    "    prompt = pipeline.tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True\n",
    "    )\n",
    "\n",
    "    terminators = [\n",
    "        pipeline.tokenizer.eos_token_id,\n",
    "        pipeline.tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "    ]\n",
    "\n",
    "    outputs = pipeline(\n",
    "        prompt,\n",
    "        max_new_tokens=1024,\n",
    "        eos_token_id=terminators,\n",
    "        do_sample=True,\n",
    "        temperature=0.1,\n",
    "        top_p=0.9,\n",
    "    )\n",
    "    #print(outputs[0][\"generated_text\"][len(prompt):])\n",
    "    return outputs[0][\"generated_text\"][len(prompt):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "564a8822",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "def parse_q_a_criteria(q_a_criteria):\n",
    "    \"\"\"\n",
    "    Converts a string of question-answer pairs into a list of formatted strings.\n",
    "\n",
    "    Parameters:\n",
    "    q_a_criteria (str): Input string containing question-answer pairs.\n",
    "\n",
    "    Returns:\n",
    "    list: List of strings combining questions and answers.\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    # Split by newline to handle individual JSON-like entries\n",
    "    for entry in q_a_criteria.split('\\n'):\n",
    "        try:\n",
    "            # Safely evaluate the string to a dictionary\n",
    "            qa_dict = ast.literal_eval(entry)\n",
    "            if 'Question' in qa_dict and 'Answer' in qa_dict:\n",
    "                # Format the question-answer pair\n",
    "                result.append(f\"{qa_dict['Question']} {qa_dict['Answer']}\")\n",
    "        except (ValueError, SyntaxError):\n",
    "            continue\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8887638f",
   "metadata": {},
   "source": [
    "Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "32685025",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nct_id</th>\n",
       "      <th>description</th>\n",
       "      <th>title</th>\n",
       "      <th>intervention_name</th>\n",
       "      <th>disease</th>\n",
       "      <th>keywords</th>\n",
       "      <th>outcome_measures</th>\n",
       "      <th>criteria</th>\n",
       "      <th>overall_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NCT04167371</td>\n",
       "      <td>Background. Rumination syndrome is characteriz...</td>\n",
       "      <td>Treament of Rumination</td>\n",
       "      <td>Biofeedback</td>\n",
       "      <td>Rumination Disorders</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>Number of rumination events after a challenge ...</td>\n",
       "      <td>Inclusion Criteria:~* Rumination syndrome~Excl...</td>\n",
       "      <td>COMPLETED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NCT01645722</td>\n",
       "      <td>The objective of this pilot study is to assess...</td>\n",
       "      <td>Enriched Autologous Fat Grafting for Treating ...</td>\n",
       "      <td>Procedure/Surgery: Enriched Fat grafting</td>\n",
       "      <td>Amputation Stumps</td>\n",
       "      <td>Fat Grafts</td>\n",
       "      <td>Treatment of Painful Amputation Sites, 1) Trea...</td>\n",
       "      <td>Inclusion Criteria:~1. Aged 18 years or older ...</td>\n",
       "      <td>COMPLETED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NCT04519957</td>\n",
       "      <td>The primary objective of this study is to asse...</td>\n",
       "      <td>Multicentre Study To Assess Safety And Efficac...</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>Treatment Resistant Depression</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>Long-term efficacy of psilocybin, Use of new a...</td>\n",
       "      <td>Inclusion Criteria:~Signed ICF Each participan...</td>\n",
       "      <td>COMPLETED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NCT04768985</td>\n",
       "      <td>This study is a multicenter, Phase I, open-lab...</td>\n",
       "      <td>A Phase I, Open-Label, Randomized, 2-Treatment...</td>\n",
       "      <td>Treatment A: Acalabrutinib tablet</td>\n",
       "      <td>Bioequivalence</td>\n",
       "      <td>Pharmacokinetics</td>\n",
       "      <td>Area under plasma concentration time curve fro...</td>\n",
       "      <td>Inclusion Criteria:~* Females must have a nega...</td>\n",
       "      <td>COMPLETED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NCT03593941</td>\n",
       "      <td>This research project will address a desperate...</td>\n",
       "      <td>Ageing Gut Brain Interactions</td>\n",
       "      <td>Standard Diet</td>\n",
       "      <td>Dementia Alzheimers</td>\n",
       "      <td>Ageing</td>\n",
       "      <td>Faecal sample Short chain fatty acid (SCFA) pr...</td>\n",
       "      <td>Inclusion Criteria:~* Resident in a care home~...</td>\n",
       "      <td>COMPLETED</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        nct_id                                        description  \\\n",
       "0  NCT04167371  Background. Rumination syndrome is characteriz...   \n",
       "1  NCT01645722  The objective of this pilot study is to assess...   \n",
       "2  NCT04519957  The primary objective of this study is to asse...   \n",
       "3  NCT04768985  This study is a multicenter, Phase I, open-lab...   \n",
       "4  NCT03593941  This research project will address a desperate...   \n",
       "\n",
       "                                               title  \\\n",
       "0                             Treament of Rumination   \n",
       "1  Enriched Autologous Fat Grafting for Treating ...   \n",
       "2  Multicentre Study To Assess Safety And Efficac...   \n",
       "3  A Phase I, Open-Label, Randomized, 2-Treatment...   \n",
       "4                      Ageing Gut Brain Interactions   \n",
       "\n",
       "                          intervention_name                         disease  \\\n",
       "0                               Biofeedback            Rumination Disorders   \n",
       "1  Procedure/Surgery: Enriched Fat grafting               Amputation Stumps   \n",
       "2                             Not Available  Treatment Resistant Depression   \n",
       "3         Treatment A: Acalabrutinib tablet                  Bioequivalence   \n",
       "4                             Standard Diet             Dementia Alzheimers   \n",
       "\n",
       "           keywords                                   outcome_measures  \\\n",
       "0     Not Available  Number of rumination events after a challenge ...   \n",
       "1        Fat Grafts  Treatment of Painful Amputation Sites, 1) Trea...   \n",
       "2     Not Available  Long-term efficacy of psilocybin, Use of new a...   \n",
       "3  Pharmacokinetics  Area under plasma concentration time curve fro...   \n",
       "4            Ageing  Faecal sample Short chain fatty acid (SCFA) pr...   \n",
       "\n",
       "                                            criteria overall_status  \n",
       "0  Inclusion Criteria:~* Rumination syndrome~Excl...      COMPLETED  \n",
       "1  Inclusion Criteria:~1. Aged 18 years or older ...      COMPLETED  \n",
       "2  Inclusion Criteria:~Signed ICF Each participan...      COMPLETED  \n",
       "3  Inclusion Criteria:~* Females must have a nega...      COMPLETED  \n",
       "4  Inclusion Criteria:~* Resident in a care home~...      COMPLETED  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read /home/trishad2/trial_searching/PoC/for_submission/data/demo_train_data.csv\n",
    "\n",
    "df = pd.read_csv(\"/home/trishad2/trial_searching/PoC/for_submission/data/demo_data.csv\")\n",
    "\n",
    "df.head()\t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40812a1",
   "metadata": {},
   "source": [
    "Q/A generation using LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bd101279",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "#apply the function to each row in the 'criteria' column\n",
    "df['q_a_criteria'] = df['criteria'].progress_apply(lambda x: parse_q_a_criteria(questions_answers(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bed68f2",
   "metadata": {},
   "source": [
    "Predefined Q/A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5b87c8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"q_a_set.append('What are the drugs used? '+ intervention)\n",
    "q_a_set.append('What is the disease treated in this trial? '+ disease)\n",
    "q_a_set.append('What is the title of the trial? '+ title)\n",
    "q_a_set.append('What are the outcome measures? '+ outcome_measures)\n",
    "q_a_set.append('What are the keywords? '+ keywords)\"\"\"\n",
    "\n",
    "#predefined questions for title, intervention, disease, outcome measures, keywords\n",
    "\n",
    "predefined_questions = [\n",
    "    'What are the drugs used? ',\n",
    "    'What is the disease treated in this trial? ',\n",
    "    'What is the title of the trial? ',\n",
    "    'What are the outcome measures? ',\n",
    "    'What are the keywords? '\n",
    "]\n",
    "\n",
    "#create q_a_intervention, q_a_disease, q_a_title, q_a_outcome_measures, q_a_keywords columns\n",
    "df['q_a_intervention'] = predefined_questions[0] + df['intervention_name']\n",
    "df['q_a_disease'] = predefined_questions[1] + df['disease']\n",
    "df['q_a_title'] = predefined_questions[2] + df['title']\n",
    "df['q_a_outcome_measures'] = predefined_questions[3] + df['outcome_measures']\n",
    "df['q_a_keywords'] = predefined_questions[4] + df['keywords']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "39d631b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a new column 'all_q_a' that combines all q_a columns\n",
    "df['all_q_a'] = df['q_a_criteria'] + df['q_a_intervention'].apply(lambda x: [x]) + df['q_a_disease'].apply(lambda x: [x]) + df['q_a_title'].apply(lambda x: [x]) + df['q_a_outcome_measures'].apply(lambda x: [x]) + df['q_a_keywords'].apply(lambda x: [x])\n",
    "df['all_q_a'] = df['all_q_a'].apply(lambda x: ' '.join(x))  # Join list of strings into a single string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f4c17b",
   "metadata": {},
   "source": [
    "Load SECRET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7fd811fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4040056/2145506959.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load('models/global_model.pth')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSdpaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the BioBERT model and tokenizer\n",
    "model_name = \"dmis-lab/biobert-base-cased-v1.1\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "state_dict = torch.load('models/global_model.pth')\n",
    "\n",
    "# Remove `module.` prefix if present\n",
    "from collections import OrderedDict\n",
    "new_state_dict = OrderedDict()\n",
    "for k, v in state_dict.items():\n",
    "    name = k[7:] if k.startswith('module.') else k  # remove 'module.' prefix\n",
    "    new_state_dict[name] = v\n",
    "\n",
    "model.load_state_dict(new_state_dict)\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "91d01d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_text(text):\n",
    "    # Tokenize input text\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)\n",
    "    \n",
    "    # Pass through the model\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    # Extract the embeddings (hidden states from the last layer)\n",
    "    # outputs.last_hidden_state -> (batch_size, sequence_length, hidden_size)\n",
    "    embeddings = outputs.last_hidden_state.to(device)\n",
    "\n",
    "    # Pool the embeddings (e.g., by taking the mean across the sequence length)\n",
    "    pooled_embeddings = embeddings.mean(dim=1)\n",
    "\n",
    "    return pooled_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044c8442",
   "metadata": {},
   "source": [
    "Get embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "22bb1ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#progress apply the embedding function to the 'all_q_a' column\n",
    "df['embedding'] = df['all_q_a'].apply(lambda x: embed_text(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93d4a16",
   "metadata": {},
   "source": [
    "Save the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7fb6f59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save as pickle\n",
    "df.to_pickle(\"/home/trishad2/trial_searching/PoC/for_submission/data/demo_data_with_embeddings.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12213334",
   "metadata": {},
   "source": [
    "KNN for each test trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1c338054",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NCT04167371', 'NCT01645722', 'NCT04519957', 'NCT04768985', 'NCT03593941']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get the embeddings for all trials from /home/trishad2/trial_searching/search/emb_dict_255572_secret_2_0.pkl\n",
    "\n",
    "import pickle\n",
    "with open('/home/trishad2/trial_searching/search/emb_dict_216587_secret_1_0.pkl', 'rb') as f:\n",
    "    emb_dict = pickle.load(f)\n",
    "\n",
    "#show first 5 keys\n",
    "list(emb_dict.keys())[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "60e2e157",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((216587, 1, 768), (1, 768))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now for the fifth trial in df, find the 5 nearest neighbors in emb_dict using cosine similarity\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "test_embedding = df.iloc[4]['embedding'].cpu().numpy()  # Convert to numpy array\n",
    "all_embeddings = np.array([emb_dict[key].cpu().numpy() for key in emb_dict])  # Convert all to numpy arrays\n",
    "\n",
    "all_embeddings.shape, test_embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "295d3ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "def get_k_nearest_neighbors(test_embedding, emb_dict, k=5):\n",
    "    \"\"\"\n",
    "    Returns the k nearest neighbors (keys) from emb_dict for the given test_embedding.\n",
    "\n",
    "    Parameters:\n",
    "    - test_embedding: torch.Tensor or np.ndarray, the embedding to compare (shape: [hidden_dim] or [1, hidden_dim])\n",
    "    - emb_dict: dict, keys are IDs and values are torch.Tensor embeddings\n",
    "    - k: int, number of nearest neighbors to return\n",
    "\n",
    "    Returns:\n",
    "    - List of tuples: (key, similarity_score), sorted by descending similarity\n",
    "    \"\"\"\n",
    "    # Convert test_embedding to numpy array and flatten to 1D\n",
    "    if hasattr(test_embedding, \"cpu\"):\n",
    "        test_embedding = test_embedding.cpu().numpy()\n",
    "    test_embedding = np.squeeze(test_embedding)  # shape: [hidden_dim]\n",
    "\n",
    "    all_keys = list(emb_dict.keys())\n",
    "    # Flatten all embeddings to 1D\n",
    "    all_embeddings = np.array([\n",
    "        np.squeeze(emb_dict[key].cpu().numpy() if hasattr(emb_dict[key], \"cpu\") else emb_dict[key])\n",
    "        for key in all_keys\n",
    "    ])  # shape: [n_samples, hidden_dim]\n",
    "\n",
    "    similarities = cosine_similarity([test_embedding], all_embeddings)[0]\n",
    "    top_k_idx = np.argsort(similarities)[::-1][:k]\n",
    "    return [(all_keys[i], similarities[i]) for i in top_k_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "97f7bd9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('NCT03593941', 0.98154485), ('NCT03256929', 0.8254221), ('NCT01020617', 0.82448864), ('NCT05008770', 0.81799597), ('NCT04135066', 0.8174179)]\n"
     ]
    }
   ],
   "source": [
    "neighbors = get_k_nearest_neighbors(test_embedding, emb_dict, k=5)\n",
    "print(neighbors)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "search",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
